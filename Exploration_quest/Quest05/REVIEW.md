## AIFFEL Campus Online Code Peer Review Templete
- 코더 : 강임구
- 리뷰어 : 김연


## PRT(Peer Review Template)
- [X]  **1. 주어진 문제를 해결하는 완성된 코드가 제출되었나요?**
    - 문제에서 요구하는 최종 결과물이 첨부되었는지 확인
    - 문제를 해결하는 완성된 코드란 프로젝트 루브릭 3개 중 2개, 퀘스트 문제 요구조건 등을 지칭
    - 해당 조건을 만족하는 코드를 캡쳐해 근거로 첨부

    ```
    # 대답을 얻는 generation
    def sentence_generation(sentence):
        # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.
        prediction = decoder_inference(sentence)

        # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.
        predicted_sentence = tokenizer.decode(
            [i for i in prediction if i < tokenizer.vocab_size])

        print('입력 : {}'.format(sentence))
        print('출력 : {}'.format(predicted_sentence))

        return predicted_sentence
    ```

>네. sentence_generation 함수를 사용하면 임의의 질문에 대해 흥미로운 대답을 얻을 수 있습니다.
    
- [X]  **2. 전체 코드에서 가장 핵심적이거나 가장 복잡하고 이해하기 어려운 부분에 작성된 주석 또는 doc string을 보고 해당 코드가 잘 이해되었나요?**
    - 해당 코드 블럭에 doc string/annotation이 달려 있는지 확인
    - 해당 코드가 무슨 기능을 하는지, 왜 그렇게 짜여진건지, 작동 메커니즘이 뭔지 기술.
    - 주석을 보고 코드 이해가 잘 되었는지 확인
    - 잘 작성되었다고 생각되는 부분을 캡쳐해 근거로 첨부합니다.

    ```
    # 2**11으로 한 이유 -> 2**10 보다 늘려봄
    tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(q_sentences + a_sentences, target_vocab_size=2**14)
    ```

>target_vocab_size를 2의 11제곱으로 선택하신 이유가 궁금했어요. target_vocab_size 조정이 전체 시퀀스에 어떤 영향을 미치는지 여쭤보니, 우선 10의 제곱부터 13 제곱까지 다양한 값으로 실험을 하셨는데 그중 11의 제곱으로 설정했을 때 최종 결과에서 쳇봇의 대답이 임의에 질문에 가장 적절하셨다고 말씀해주셨어요.
        
- [X]  **3. 에러가 난 부분을 디버깅하여 문제를 “해결한 기록을 남겼거나”, ”새로운 시도 또는 추가 실험을 수행”해봤나요?**
    - 문제 원인 및 해결 과정을 잘 기록하였는지 확인
    - 문제에서 요구하는 조건에 더해 추가적으로 수행한 나만의 시도, 실험이 기록되어 있는지 확인
    - 잘 작성되었다고 생각되는 부분을 캡쳐해 근거로 첨부합니다.
        
>전체적으로 에러없이 원활하게 잘 진행되었습니다.

- [X]  **4. 회고를 잘 작성했나요?**
    - 주어진 문제를 해결하는 완성된 코드 내지 프로젝트 결과물에 대해 배운점과 아쉬운점, 느낀점 등이 기록되어 있는지 확인
    - 전체 코드 실행 플로우를 그래프로 그려서 이해를 돕고 있는지 확인
    - 잘 작성되었다고 생각되는 부분을 캡쳐해 근거로 첨부합니다.

```
트랜스포머를 이해하는게 너무 어려웠음
코드 따라가기가 극한으로 어려워진 노드 내용
vocab_size와 MAX_LENGTH에 따라 수치가 살짝살짝 변하는데 어떠한 영향을 미치는지 모르겠음
뭔가 답변이 기분나쁨... 그냥 기분나빠... 원본 데이터에는 따듯하게 답변한거 같은데 챗봇의 답변은 그냥 차가운느낌
지워진 결과중 하나는 크리스마스에 대한 답변으로 '남에게 피해주고 생각해요' 라는 출력값이 나왔음
지금은 형태소 분석을 통한 전처리가 아니기 때문에 다음에 실험을 한다면 형태소 분석 전처리를 해볼 생각
추가적인 데이터가 구해진다면 더하는것도 좋을거라 봄
```

>README.md 에 회고를 작성해주셨고, 모델 성능의 최적화를 조정하는 과정별로 파일을 저장하셨으며 각 실험에 대한 결과를 회고와 함께 이미지로 보여주셨습니다. 실험 과정과 결과를 보면 모델에 다양한 변화를 시도하셨고 그러한 시도가 어떤 결과를 도출했는지 알 수 있으며, 각 결과에 대해서도 비교할 수 있었습니다.
        
- [X]  **5. 코드가 간결하고 효율적인가요?**
    - 파이썬 스타일 가이드 (PEP8) 를 준수하였는지 확인
    - 하드코딩을 하지않고 함수화, 모듈화가 가능한 부분은 함수를 만들거나 클래스로 짰는지
    - 코드 중복을 최소화하고 범용적으로 사용할 수 있도록 함수화했는지
    - 잘 작성되었다고 생각되는 부분을 캡쳐해 근거로 첨부합니다.

```
dataset = tf.data.Dataset.from_tensor_slices((
    {
        'inputs': questions,
        'dec_inputs': answers[:, :-1]
    },
    {
        'outputs': answers[:, 1:]
    },
))
```

>대부분 함수화로 디자인되었고, 간결한 코드로 작성되었습니다.

## 참고 링크 및 코드 개선

>target_vocab_size 조정이 결과에 미치는 영향에 대해 알 수 있어서 유익했습니다. 다이나믹하게 시도하신 과정들을 살펴볼 수 있어서 좋았습니다. 수고하셨습니다.
