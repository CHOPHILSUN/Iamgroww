{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c86d9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.22.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac9492d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "936b1c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240  images to be resized.\n",
      "240  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f719a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252  images to be resized.\n",
      "252  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd13862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242  images to be resized.\n",
      "242  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a92c796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 734 입니다.\n",
      "x_train shape: (734, 28, 28, 3)\n",
      "y_train shape: (734,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=734):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6388770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[112])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e437f727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 122,051\n",
      "Trainable params: 122,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18de282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 1.0968 - accuracy: 0.3801\n",
      "Epoch 2/15\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 1.0089 - accuracy: 0.5232\n",
      "Epoch 3/15\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 0.8415 - accuracy: 0.6199\n",
      "Epoch 4/15\n",
      "23/23 [==============================] - 1s 38ms/step - loss: 0.6743 - accuracy: 0.7180\n",
      "Epoch 5/15\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 0.5530 - accuracy: 0.7561\n",
      "Epoch 6/15\n",
      "23/23 [==============================] - 1s 39ms/step - loss: 0.4721 - accuracy: 0.8161\n",
      "Epoch 7/15\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 0.3910 - accuracy: 0.8515\n",
      "Epoch 8/15\n",
      "23/23 [==============================] - 1s 39ms/step - loss: 0.3300 - accuracy: 0.8896\n",
      "Epoch 9/15\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 0.2496 - accuracy: 0.9332\n",
      "Epoch 10/15\n",
      "23/23 [==============================] - 1s 39ms/step - loss: 0.2468 - accuracy: 0.9155\n",
      "Epoch 11/15\n",
      "23/23 [==============================] - 1s 42ms/step - loss: 0.1931 - accuracy: 0.9428\n",
      "Epoch 12/15\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 0.1947 - accuracy: 0.9278\n",
      "Epoch 13/15\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 0.1361 - accuracy: 0.9673\n",
      "Epoch 14/15\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 0.1159 - accuracy: 0.9659\n",
      "Epoch 15/15\n",
      "23/23 [==============================] - 1s 38ms/step - loss: 0.1116 - accuracy: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd9867398e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "052ab170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12  images to be resized.\n",
      "12  images resized.\n",
      "13  images to be resized.\n",
      "13  images resized.\n",
      "13  images to be resized.\n",
      "13  images resized.\n",
      "학습데이터(x_train)의 이미지 개수는 38 입니다.\n",
      "x_test shape: (38, 28, 28, 3)\n",
      "y_test shape: (38,)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "\n",
    "def load_data_t(img_path, number_of_data=38):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data_t(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "#시험용 데이터 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cd28b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 2.7910 - accuracy: 0.6053\n",
      "test_loss: 2.7910404205322266\n",
      "test_accuracy: 0.6052631735801697\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss}\")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f52c337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 2.7910 - accuracy: 0.6053\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test_norm,y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70b516c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.7910404205322266\n",
      "Accuracy: 0.6052631735801697\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss:\", results[0])\n",
    "print(\"Accuracy:\", results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be7fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
